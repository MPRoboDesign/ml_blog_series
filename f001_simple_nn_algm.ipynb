{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "722c8e91-006b-44f5-bf7f-496dfda8bb14",
   "metadata": {},
   "source": [
    "# Machine Learning Series: Simple Neural Network Pipeline 1\n",
    "\n",
    "- &copy;2024 Madhava Pandiyan CN (MPtheRoboticist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba4b9f-9039-4133-ab1a-2d90316e40b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0. Installations\n",
    "\n",
    "- **Jupyter Notebook Version:** 7.0.6\n",
    "- **IPython Version:** 8.12.3\n",
    "- **Tensorflow version:** 2.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5322a2-7808-44fc-ad1c-ebe0f823b083",
   "metadata": {},
   "source": [
    "## 1. Import  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095bf88f-5b85-4add-8377-2670decd5596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 00:00:03.279314: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
      "2024-08-11 00:00:03.279354: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154bb222-fff9-49b7-a800-d34b5e5f88ba",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "From **[1]**\n",
    "\n",
    "- **x_train:** _uint8_ NumPy array of grayscale image data with shapes (60000, 28, 28), containing the training data. Pixel values range from 0 to 255.\n",
    "\n",
    "- **y_train:** _uint8_ NumPy array of digit labels (integers in range 0-9) with shape (60000,) for the training data.\n",
    "\n",
    "- **x_test:** _uint8_ NumPy array of grayscale image data with shapes (10000, 28, 28), containing the test data. Pixel values range from 0 to 255.\n",
    "\n",
    "- **y_test:** _uint8_ NumPy array of digit labels (integers in range 0-9) with shape (10000,) for the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a4400a-98ef-419b-a568-afff2a6c9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data to following variables\n",
    "'''\n",
    "x_train: 60000 grayscale images each made of 28x28 pixels.\n",
    "y_train: label for all 60000 images split among 10 classes.\n",
    "\n",
    "x_test: 10000 grayscale images each made of 28x28 pixels.\n",
    "y_test: label for all 10000 images split among 10 classes.\n",
    "'''\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06991fb7-df4e-4f36-bcfe-123ab9806a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_train:  (60000, 28, 28)\n",
      "Size of y_train:  (60000,)\n",
      "Size of x_test:\t  (10000, 28, 28)\n",
      "Size of y_test:\t  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the size of each variable\n",
    "print(\"Size of x_train: \", x_train.shape)\n",
    "print(\"Size of y_train: \", y_train.shape)\n",
    "print(\"Size of x_test:\\t \", x_test.shape)\n",
    "print(\"Size of y_test:\\t \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ef70431-0206-42d3-9720-657719a3ae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "# Checking the value of y_train before pre-processing.\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dab10f-7d6d-4b1c-8ea0-e5b24b9eff1a",
   "metadata": {},
   "source": [
    "## 3. Pre-processing the data\n",
    "\n",
    "- **x_train_:** Changes the range of _x_train_. New range --> 0 to 1\n",
    "- **x_test_:** Changes the range of _x_test_. New range --> 0 to 1\n",
    "- **y_train_:** Changes _y_train_ from integer encoding to _one-hot encoding_.\n",
    "- **y_test_:** Changes _y_test_ from integer encoding to _one-hot encoding_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619167eb-0f49-4ec5-aa46-2ccb0a127e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ = x_train.astype('float32') / 255\n",
    "x_test_ = x_test.astype('float32') / 255\n",
    "\n",
    "# The function to_categorical converts values to binary.\n",
    "# Here the class label is converted to \n",
    "# one-hot encoding format.\n",
    "# 10 indicates that there are 10 classes.\n",
    "y_train_ = to_categorical(y_train, 10)\n",
    "y_test_ = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b4dbbc-ebbd-4a7a-a4fc-b3b39c8bd5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_train after preprocessing:\t  (60000, 28, 28)\n",
      "Size of y_train after preprocessing:\t  (60000, 10)\n",
      "Size of x_test after preprocessing:\t  (10000, 28, 28)\n",
      "Size of y_test after preprocessing:\t  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Checking the size of each variable\n",
    "print(\"Size of x_train after preprocessing:\\t \", x_train_.shape)\n",
    "print(\"Size of y_train after preprocessing:\\t \", y_train_.shape)\n",
    "print(\"Size of x_test after preprocessing:\\t \", x_test_.shape)\n",
    "print(\"Size of y_test after preprocessing:\\t \", y_test_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0c7d2b-9b5d-4b38-b82f-64c7da533e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Checking the value of y_train after pre-processing.\n",
    "print(y_train_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621805ba-f0e3-458f-a2a4-ba3e51b781d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Neural Network Architecture\n",
    "\n",
    "**Sequential [2]:**\n",
    "- Note: can be imported either from **tensorflow.keras.models.Sequential** or from **tensorflow.keras.Sequential**.\n",
    "- **Sequential** groups a linear stack of layers into a **Model**.\n",
    "\n",
    "**Flatten [3]:**\n",
    "- **Flatten():** Flattens the input. Does not affect the batch size.\n",
    "- i.e. here since input shape is (28, 28), the output would be (None, 784).\n",
    "- 28 x 28 = 784\n",
    "\n",
    "**Dense [4]:**\n",
    "- **Dense(units, activation):** Just your regular densely-connected NN layer.\n",
    "- **units:** Positive integer, dimensionality of the output space.\n",
    "- **activation:** Activation function to use. Check [5] for list of available in-built activation functions.\n",
    "\n",
    "**ReLU [6]:**\n",
    "- ReLU --> Rectified Linear Unit\n",
    "- The Rectified Linear Unit (ReLU for short) is a linear activation function that was introduced to solve the vanishing gradient problem and has become increasingly popular in applications in recent years. In short, it keeps positive values and sets negative input values equal to zero.\n",
    "\n",
    "                        f(x) = max{0, x}\n",
    "\n",
    "**Softmax [7]:**\n",
    "- The elements of the output vector are in range [0, 1] and sum to 1.\n",
    "\n",
    "                        f(x) = exp(x) / sum(exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3e8ebb6-ca94-427b-9eef-1b4f7453a44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 00:00:42.920147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-08-11 00:00:43.365623: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-11 00:00:43.365657: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (madhava-pandiyan): /proc/driver/nvidia/version does not exist\n",
      "2024-08-11 00:00:43.366117: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-11 00:00:43.542383: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2394465000 Hz\n",
      "2024-08-11 00:00:43.543462: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3315070 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-11 00:00:43.543531: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf150c79-d51e-4c0b-9184-591f48f1e4b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Compile the architecture\n",
    "\n",
    "**Compile [2]:**\n",
    "- Configures the model for training.\n",
    "- Arguments: Optimizer, Loss, Metrics.\n",
    "\n",
    "**Optimizer:**\n",
    "- Check [8] for list of in-built optimizers.\n",
    "\n",
    "**Loss:**\n",
    "- Check [9] for list of in-built loss functions.\n",
    "\n",
    "**Adam:**\n",
    "\n",
    "- With reference to [10], Adam Optimizer algorithm is as follows:\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*zfdW5zAyQxge85gA_mFPYg.png\" alt=\"adam_optimizer\" width=\"600\"/>\n",
    "\n",
    "**Categorical Cross entropy:**\n",
    "\n",
    "- With reference to [11], Categorical Cross Entropy is as follows:\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/0*PSuYoaQICXefd6qA.png\" alt=\"categorical_cross_entropy\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19172f9b-013f-488f-8c70-f527a628889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cb2be-9d3b-4585-88c9-70d8ae76e496",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6. Train the model\n",
    "\n",
    "**Fit [2]:**\n",
    "\n",
    "- Trains the model for a fixed number of epochs (dataset iterations).\n",
    "- **Batch size:** Number of samples per gradient update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986805ce-ff71-48d4-b53e-0fc7d0f731d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 00:01:10.109086: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2377\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1035\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0727\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0562\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0425\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0367\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0301\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0263\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0212\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0209\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0171\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0168\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0146\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0134\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0143\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0118\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0124\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0124\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0108\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f972c095040>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_, y_train_, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a3972-e0e3-44a5-9a77-8a90cfc3a698",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7. Evaluate\n",
    "\n",
    "**Evaluate [2]:**\n",
    "\n",
    "- Returns the loss value & metrics values for the model in test mode.\n",
    "- **Note:** Here metrics value has not been called as we didn't specify one during compiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9a3c7ab-b82a-4848-a809-d89a9a729d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1253\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(x_test_, y_test_, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0708a5a-c8bc-4a04-8acf-031539e405a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.12531176209449768\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: \", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23840376-124f-4016-b389-ea162b1f9378",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 8. Reference\n",
    "\n",
    "[1] - **tf.keras.datasets.mnist.load_data**(https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data) \n",
    "    \n",
    "[2] - **tf.keras.Sequential** (https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)\n",
    "\n",
    "[3] - **tf.keras.layers.Flatten** (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)\n",
    "\n",
    "[4] - **tf.keras.layers.Dense** (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)\n",
    "\n",
    "[5] - **tf.keras.activations** (https://www.tensorflow.org/api_docs/python/tf/keras/activations)\n",
    "\n",
    "[6] - **What is ReLU-function (Rectified Linear Unit)?** (https://databasecamp.de/en/ml/relu-en)\n",
    "\n",
    "[7] - **tf.keras.activations.softmax** (https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax)\n",
    "\n",
    "[8] - **tf.keras.optimizers** (https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)\n",
    "\n",
    "[9] - **tf.keras.losses** (https://www.tensorflow.org/api_docs/python/tf/keras/losses)\n",
    "\n",
    "[10] - **Everything you need to know about Adam Optimizer** (https://medium.com/@nishantnikhil/adam-optimizer-notes-ddac4fd7218)\n",
    "\n",
    "[11] - **Categorical cross-entropy loss â€” The most important loss function** (https://neuralthreads.medium.com/categorical-cross-entropy-loss-the-most-important-loss-function-d3792151d05b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
